# 100 Days of Data Engineering

Welcome to the **100 Days of Data Engineering** challenge! This repository documents my journey of mastering key data engineering concepts, tools, and technologies over the course of 100 days. Each day, I will tackle a specific topic, learn the theory, and practice through hands-on exercises.

## Technologies and Topics Covered

Throughout this challenge, I will focus on the following areas:

- **Python**: Core programming language for data engineering.
- **Pandas**: Data manipulation and analysis library.
- **SQL**: Structured Query Language for relational databases.
- **NoSQL**: Databases like MongoDB for unstructured data.
- **Linux**: Command-line tools and scripting.
- **ETL / Data Pipeline**: Building and managing data workflows.
- **Data Warehousing / Snowflake**: Designing and managing data warehouses using Snowflake.
- **Apache Spark**: Big data processing framework.
- **Apache Kafka**: Distributed event streaming platform.
- **Apache Airflow**: Workflow orchestration platform.
- **Power BI**: Business analytics tool.
- **AWS**: Cloud services for data engineering.
- **Git**: Version control for managing code and projects.

## Daily Progress

### Day 1 (7 Aug 2024)
- **Add GitHub basics and handwritten notes**: Started by learning GitHub fundamentals and documenting them through handwritten notes.
- **Add Python notes, study, and practice chapters 1-6**: Organized Python notes into three folders covering chapters 1-19 and completed learning and practice exercises for chapters 1-6.

> **Note:** Python notes were sourced from [Code and Debug](https://www.codeanddebug.in).

## How to Use This Repository

- Each folder is organized with relevant notes, code, and practice exercises.
- Check out the specific technology folders for detailed learning paths and examples.
- Feel free to explore, learn, and contribute!

## License

This project is licensed under the MIT License.
